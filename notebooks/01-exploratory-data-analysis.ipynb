{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”· PART 1: Exploratory Data Analysis ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we analyze our given external datasets through a **basic comprehensive** lens: we manipulate, curate, and prepare data in order to ask critical questions and gain an effective understanding of how to perform higher-level prediction-driven data modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”µ TABLE OF CONTENTS ðŸ”µ <a name=\"TOC\"></a>\n",
    "\n",
    "Use this **table of contents** to navigate the various sections of the preprocessing notebook.\n",
    "\n",
    "#### 1. [Section A: Imports and Initializations](#section-A)\n",
    "\n",
    "    All necessary imports and object instantiations for data preprocessing.\n",
    "\n",
    "#### 2. [Section B: Manipulating Our Data](#section-B)\n",
    "\n",
    "    Data manipulation operations, including (but not limited to) \n",
    "    null value imputation and data cleaning. \n",
    "\n",
    "#### 3. [Section C: Visualizing Trends Across Our Data](#section-C)\n",
    "\n",
    "    Data visualizations to outline trends and patterns \n",
    "    inherent across our data that may mandate further analysis.\n",
    "\n",
    "#### 4. [Section D: Saving Our Interim Datasets](#section-D)\n",
    "\n",
    "    Saving preprocessed data states for further access.\n",
    "\n",
    "#### 5. [Appendix: Supplementary Custom Objects](#appendix)\n",
    "\n",
    "    Custom object architectures used throughout the data preprocessing.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section A: Imports and Initializations <a name=\"section-A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Imports for Data Manipulation and Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized Imports for Deep Learning Architectures and Supporting Structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, InputLayer, Reshape, Conv1D, MaxPool1D, SeparableConv2D\n",
    "from keras.applications import MobileNetV2, VGG19\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized Imports for Model Evaluation and Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized Imports for Globular File/Directory Navigation and Script Timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized Imports for Image Modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Algorithmic Structures for Processed Data Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../source/structures\")\n",
    "\n",
    "# TODO: Place custom structures from `../source/structures` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section B: Manipulating Our Data <a name=\"section-B\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATH = \"/Volumes/Bianca/DEVELOPER/data-science/Malaria-Imaging\"\n",
    "RAWPATH, INTPATH = \"datasets/1-raw/cell_images/\", \"datasets/2-interim/cell_images/\"\n",
    "POSITIVE, NEGATIVE = \"Parasitized\", \"Uninfected\"\n",
    "TRAIN, VALID, TEST = \"Training\", \"Validation\", \"Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATHS_RAW = {\n",
    "    POSITIVE: os.path.join(DIRPATH, RAWPATH, POSITIVE),\n",
    "    NEGATIVE: os.path.join(DIRPATH, RAWPATH, NEGATIVE),\n",
    "}\n",
    "\n",
    "DIRPATHS_INT = {\n",
    "    POSITIVE: {\n",
    "        TRAIN: os.path.join(DIRPATH, INTPATH, POSITIVE, TRAIN),\n",
    "        VALID: os.path.join(DIRPATH, INTPATH, POSITIVE, VALID),\n",
    "        TEST:  os.path.join(DIRPATH, INTPATH, POSITIVE, TEST)\n",
    "    },\n",
    "    NEGATIVE: {\n",
    "        TRAIN: os.path.join(DIRPATH, INTPATH, NEGATIVE, TRAIN),\n",
    "        VALID: os.path.join(DIRPATH, INTPATH, NEGATIVE, VALID),\n",
    "        TEST:  os.path.join(DIRPATH, INTPATH, NEGATIVE, TEST)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of interim datasets for ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for position, filename in enumerate(os.listdir(DIRPATHS_RAW[POSITIVE])):\n",
    "    newpath = \"{}_{}.jpg\".format(POSITIVE, position)\n",
    "    source = os.path.join(DIRPATHS_RAW[POSITIVE], filename)\n",
    "    destination = os.path.join(DIRPATH, INTPATH, POSITIVE, newpath)\n",
    "    shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for position, filename in enumerate(os.listdir(DIRPATHS_RAW[NEGATIVE])):\n",
    "    newpath = \"{}_{}.jpg\".format(NEGATIVE, position)\n",
    "    source = os.path.join(DIRPATHS_RAW[NEGATIVE], filename)\n",
    "    destination = os.path.join(DIRPATH, INTPATH, NEGATIVE, newpath)\n",
    "    shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Initialization of Interim Datasets for Ingestion: **Parasitized Images**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\"{}_{}.jpg\".format(POSITIVE, position) for position in range(3000)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, POSITIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[POSITIVE][TRAIN], image)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "images = [\"{}_{}.jpg\".format(POSITIVE, position) for position in range(3000, 4000)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, POSITIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[POSITIVE][VALID], image)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "images = [\"{}_{}.jpg\".format(POSITIVE, position) for position in range(4000, 4500)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, POSITIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[POSITIVE][TEST], image)\n",
    "    shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Initialization of Interim Datasets for Ingestion: **Uninfected Images**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\"{}_{}.jpg\".format(NEGATIVE, position) for position in range(3000)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, NEGATIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[NEGATIVE][TRAIN], image)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "images = [\"{}_{}.jpg\".format(NEGATIVE, position) for position in range(3000, 4000)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, NEGATIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[NEGATIVE][VALID], image)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "images = [\"{}_{}.jpg\".format(NEGATIVE, position) for position in range(4000, 4500)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, NEGATIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[NEGATIVE][TEST], image)\n",
    "    shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting Images for Pipeline Ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1.0 / 255.0,\n",
    "                                    validation_split=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation: **Training Data**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SUB_BATCH_SIZE = BATCH_SIZE / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2010 images belonging to 1 classes.\n",
      "Found 2010 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "positive_training_generator = data_generator.flow_from_directory(directory=os.path.join(DIRPATH, INTPATH, POSITIVE),\n",
    "                                                                 classes=[TRAIN], \n",
    "                                                                 target_size=(128, 128),\n",
    "                                                                 class_mode=\"binary\",\n",
    "                                                                 subset=\"training\",\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "negative_training_generator = data_generator.flow_from_directory(directory=os.path.join(DIRPATH, INTPATH, NEGATIVE),\n",
    "                                                                 classes=[TRAIN],\n",
    "                                                                 target_size=(128, 128),\n",
    "                                                                 class_mode=\"binary\",\n",
    "                                                                 subset=\"training\",\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "training_generator = MergedGenerator(BATCH_SIZE, \n",
    "                                     generators=[positive_training_generator, negative_training_generator], \n",
    "                                     sub_batch_size=[SUB_BATCH_SIZE] * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation: **Validation Data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        ImageDataGenerator\n",
       "\u001b[0;31mString form:\u001b[0m <tensorflow.python.keras.preprocessing.image.ImageDataGenerator object at 0x7f8a24192370>\n",
       "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Generate batches of tensor image data with real-time data augmentation.\n",
       "\n",
       " The data will be looped over (in batches).\n",
       "\n",
       "Arguments:\n",
       "    featurewise_center: Boolean.\n",
       "        Set input mean to 0 over the dataset, feature-wise.\n",
       "    samplewise_center: Boolean. Set each sample mean to 0.\n",
       "    featurewise_std_normalization: Boolean.\n",
       "        Divide inputs by std of the dataset, feature-wise.\n",
       "    samplewise_std_normalization: Boolean. Divide each input by its std.\n",
       "    zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n",
       "    zca_whitening: Boolean. Apply ZCA whitening.\n",
       "    rotation_range: Int. Degree range for random rotations.\n",
       "    width_shift_range: Float, 1-D array-like or int\n",
       "        - float: fraction of total width, if < 1, or pixels if >= 1.\n",
       "        - 1-D array-like: random elements from the array.\n",
       "        - int: integer number of pixels from interval\n",
       "            `(-width_shift_range, +width_shift_range)`\n",
       "        - With `width_shift_range=2` possible values\n",
       "            are integers `[-1, 0, +1]`,\n",
       "            same as with `width_shift_range=[-1, 0, +1]`,\n",
       "            while with `width_shift_range=1.0` possible values are floats\n",
       "            in the interval [-1.0, +1.0).\n",
       "    height_shift_range: Float, 1-D array-like or int\n",
       "        - float: fraction of total height, if < 1, or pixels if >= 1.\n",
       "        - 1-D array-like: random elements from the array.\n",
       "        - int: integer number of pixels from interval\n",
       "            `(-height_shift_range, +height_shift_range)`\n",
       "        - With `height_shift_range=2` possible values\n",
       "            are integers `[-1, 0, +1]`,\n",
       "            same as with `height_shift_range=[-1, 0, +1]`,\n",
       "            while with `height_shift_range=1.0` possible values are floats\n",
       "            in the interval [-1.0, +1.0).\n",
       "    brightness_range: Tuple or list of two floats. Range for picking\n",
       "        a brightness shift value from.\n",
       "    shear_range: Float. Shear Intensity\n",
       "        (Shear angle in counter-clockwise direction in degrees)\n",
       "    zoom_range: Float or [lower, upper]. Range for random zoom.\n",
       "        If a float, `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n",
       "    channel_shift_range: Float. Range for random channel shifts.\n",
       "    fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}.\n",
       "        Default is 'nearest'.\n",
       "        Points outside the boundaries of the input are filled\n",
       "        according to the given mode:\n",
       "        - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n",
       "        - 'nearest':  aaaaaaaa|abcd|dddddddd\n",
       "        - 'reflect':  abcddcba|abcd|dcbaabcd\n",
       "        - 'wrap':  abcdabcd|abcd|abcdabcd\n",
       "    cval: Float or Int.\n",
       "        Value used for points outside the boundaries\n",
       "        when `fill_mode = \"constant\"`.\n",
       "    horizontal_flip: Boolean. Randomly flip inputs horizontally.\n",
       "    vertical_flip: Boolean. Randomly flip inputs vertically.\n",
       "    rescale: rescaling factor. Defaults to None.\n",
       "        If None or 0, no rescaling is applied,\n",
       "        otherwise we multiply the data by the value provided\n",
       "        (after applying all other transformations).\n",
       "    preprocessing_function: function that will be applied on each input.\n",
       "        The function will run after the image is resized and augmented.\n",
       "        The function should take one argument:\n",
       "        one image (Numpy tensor with rank 3),\n",
       "        and should output a Numpy tensor with the same shape.\n",
       "    data_format: Image data format,\n",
       "        either \"channels_first\" or \"channels_last\".\n",
       "        \"channels_last\" mode means that the images should have shape\n",
       "        `(samples, height, width, channels)`,\n",
       "        \"channels_first\" mode means that the images should have shape\n",
       "        `(samples, channels, height, width)`.\n",
       "        It defaults to the `image_data_format` value found in your\n",
       "        Keras config file at `~/.keras/keras.json`.\n",
       "        If you never set it, then it will be \"channels_last\".\n",
       "    validation_split: Float. Fraction of images reserved for validation\n",
       "        (strictly between 0 and 1).\n",
       "    dtype: Dtype to use for the generated arrays.\n",
       "\n",
       "Examples:\n",
       "\n",
       "Example of using `.flow(x, y)`:\n",
       "\n",
       "```python\n",
       "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
       "y_train = np_utils.to_categorical(y_train, num_classes)\n",
       "y_test = np_utils.to_categorical(y_test, num_classes)\n",
       "datagen = ImageDataGenerator(\n",
       "    featurewise_center=True,\n",
       "    featurewise_std_normalization=True,\n",
       "    rotation_range=20,\n",
       "    width_shift_range=0.2,\n",
       "    height_shift_range=0.2,\n",
       "    horizontal_flip=True)\n",
       "# compute quantities required for featurewise normalization\n",
       "# (std, mean, and principal components if ZCA whitening is applied)\n",
       "datagen.fit(x_train)\n",
       "# fits the model on batches with real-time data augmentation:\n",
       "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
       "                    steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
       "# here's a more \"manual\" example\n",
       "for e in range(epochs):\n",
       "    print('Epoch', e)\n",
       "    batches = 0\n",
       "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
       "        model.fit(x_batch, y_batch)\n",
       "        batches += 1\n",
       "        if batches >= len(x_train) / 32:\n",
       "            # we need to break the loop by hand because\n",
       "            # the generator loops indefinitely\n",
       "            break\n",
       "```\n",
       "\n",
       "Example of using `.flow_from_directory(directory)`:\n",
       "\n",
       "```python\n",
       "train_datagen = ImageDataGenerator(\n",
       "        rescale=1./255,\n",
       "        shear_range=0.2,\n",
       "        zoom_range=0.2,\n",
       "        horizontal_flip=True)\n",
       "test_datagen = ImageDataGenerator(rescale=1./255)\n",
       "train_generator = train_datagen.flow_from_directory(\n",
       "        'data/train',\n",
       "        target_size=(150, 150),\n",
       "        batch_size=32,\n",
       "        class_mode='binary')\n",
       "validation_generator = test_datagen.flow_from_directory(\n",
       "        'data/validation',\n",
       "        target_size=(150, 150),\n",
       "        batch_size=32,\n",
       "        class_mode='binary')\n",
       "model.fit_generator(\n",
       "        train_generator,\n",
       "        steps_per_epoch=2000,\n",
       "        epochs=50,\n",
       "        validation_data=validation_generator,\n",
       "        validation_steps=800)\n",
       "```\n",
       "\n",
       "Example of transforming images and masks together.\n",
       "\n",
       "```python\n",
       "# we create two instances with the same arguments\n",
       "data_gen_args = dict(featurewise_center=True,\n",
       "                     featurewise_std_normalization=True,\n",
       "                     rotation_range=90,\n",
       "                     width_shift_range=0.1,\n",
       "                     height_shift_range=0.1,\n",
       "                     zoom_range=0.2)\n",
       "image_datagen = ImageDataGenerator(**data_gen_args)\n",
       "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
       "# Provide the same seed and keyword arguments to the fit and flow methods\n",
       "seed = 1\n",
       "image_datagen.fit(images, augment=True, seed=seed)\n",
       "mask_datagen.fit(masks, augment=True, seed=seed)\n",
       "image_generator = image_datagen.flow_from_directory(\n",
       "    'data/images',\n",
       "    class_mode=None,\n",
       "    seed=seed)\n",
       "mask_generator = mask_datagen.flow_from_directory(\n",
       "    'data/masks',\n",
       "    class_mode=None,\n",
       "    seed=seed)\n",
       "# combine generators into one which yields image and masks\n",
       "train_generator = zip(image_generator, mask_generator)\n",
       "model.fit_generator(\n",
       "    train_generator,\n",
       "    steps_per_epoch=2000,\n",
       "    epochs=50)\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 330 images belonging to 1 classes.\n",
      "Found 330 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "positive_validation_generator = data_generator.flow_from_directory(directory=os.path.join(DIRPATH, INTPATH, POSITIVE),\n",
    "                                                                   classes=[VALID],\n",
    "                                                                   target_size=(128, 128),\n",
    "                                                                   class_mode=\"binary\",\n",
    "                                                                   subset=\"validation\",\n",
    "                                                                   shuffle=True,\n",
    "                                                                   batch_size=32)\n",
    "\n",
    "negative_validation_generator = data_generator.flow_from_directory(directory=os.path.join(DIRPATH, INTPATH, NEGATIVE),\n",
    "                                                                   classes=[VALID],\n",
    "                                                                   target_size=(128, 128),\n",
    "                                                                   class_mode=\"binary\",\n",
    "                                                                   subset=\"validation\",\n",
    "                                                                   shuffle=True,\n",
    "                                                                   batch_size=32)\n",
    "\n",
    "training_generator = MergedGenerator(BATCH_SIZE, \n",
    "                                     generators=[positive_validation_generator, negative_validation_generator], \n",
    "                                     sub_batch_size=[SUB_BATCH_SIZE] * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Instantiation and Testing: **Depth-Wise Separable CNN (DS-CNN)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 126, 126, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 61, 61, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_6 (Separabl (None, 28, 28, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 12, 12, 128)       8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 311,425\n",
      "Trainable params: 311,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_LENGTH = (128, 128, 3)\n",
    "\n",
    "model_dscnn = Sequential()\n",
    "\n",
    "model_dscnn.add(Conv2D(16, (3, 3), activation=\"relu\", input_shape=INPUT_LENGTH))\n",
    "model_dscnn.add(MaxPool2D(2, 2))\n",
    "model_dscnn.add(Dropout(0.2))\n",
    "\n",
    "model_dscnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model_dscnn.add(MaxPool2D(2, 2))\n",
    "model_dscnn.add(Dropout(0.2))\n",
    "\n",
    "model_dscnn.add(SeparableConv2D(64, (3, 3), activation=\"relu\"))\n",
    "model_dscnn.add(MaxPool2D(2, 2))\n",
    "model_dscnn.add(Dropout(0.3))\n",
    "\n",
    "model_dscnn.add(SeparableConv2D(128, (3, 3), activation=\"relu\"))\n",
    "model_dscnn.add(MaxPool2D(2, 2))\n",
    "model_dscnn.add(Dropout(0.3))\n",
    "\n",
    "model_dscnn.add(Flatten())\n",
    "model_dscnn.add(Dense(64, activation=\"relu\"))\n",
    "model_dscnn.add(Dropout(0.5))\n",
    "\n",
    "model_dscnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model_dscnn.compile(optimizer=optimizer,\n",
    "                    loss=\"binary_crossentropy\",\n",
    "                    metrics=[\"accuracy\"])\n",
    "model_dscnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stoppage = EarlyStopping(monitor=\"val_loss\",\n",
    "                               patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Fulfillment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.9121"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:941 test_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:909 test_step  **\n        y_pred = self(x, training=False)\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:155 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer sequential_3 expects 1 inputs, but it received 4 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-df88c4d7c001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model_dscnn.fit_generator(training_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stoppage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \"\"\"\n\u001b[1;32m   1464\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit_generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1466\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    860\u001b[0m           val_x, val_y, val_sample_weight = (\n\u001b[1;32m    861\u001b[0m               data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0;32m--> 862\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    863\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:941 test_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:909 test_step  **\n        y_pred = self(x, training=False)\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /Users/aakashsudhakar/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:155 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer sequential_3 expects 1 inputs, but it received 4 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "history = model_dscnn.fit(training_generator,\n",
    "                          epochs=20,\n",
    "                          steps_per_epoch=len(training_generator),\n",
    "                          validation_data=(validation_generator),\n",
    "                          callbacks=[early_stoppage],\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of Training and Validation Accuracy Measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-0148ea617d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_training_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay_training_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "display_training_scores(history, which=\"accuracy\")\n",
    "display_training_scores(history, which=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model State Save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Bianca/DEVELOPER/data-science/Malaria-Imaging/models/malaria_imaging_dscnn_v01.h5'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATEPATH, STATEVERSION = \"models\", 1\n",
    "\n",
    "model_state = \"malaria_imaging_dscnn_v{:02d}.h5\".format(STATEVERSION)\n",
    "\n",
    "model_dscnn.save_weights(os.path.join(DIRPATH, STATEPATH, model_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Appendix: Supplementary Custom Objects <a name=\"appendix\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_generator(generator1, generator2):\n",
    "    while True:\n",
    "        yield(next(generator1), next(generator2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_scores(history, which=\"accuracy\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if which == \"accuracy\":\n",
    "        plt.plot(history.history[\"accuracy\"], label=\"Training\", marker=\"*\", linewidth=3)\n",
    "        plt.plot(history.history[\"val_accuracy\"], label=\"Validation\", marker=\"o\", linewidth=3)\n",
    "        plt.title(\"Accuracy Assessment: Training vs. Validation\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "    elif which == \"loss\":\n",
    "        plt.plot(history.history[\"loss\"], label=\"Training\", marker=\"*\", linewidth=3)\n",
    "        plt.plot(history.history[\"val_loss\"], label=\"Validation\", marker=\"o\", linewidth=3)\n",
    "        plt.title(\"Loss Assessment: Training vs. Validation\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend(fontsize=\"x-large\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergedGenerator(Sequence):\n",
    "    def __init__(self, batch_size, generators=[], sub_batch_size=[]):\n",
    "        self.generators = generators\n",
    "        self.sub_batch_size = sub_batch_size\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return int(\n",
    "            sum([(len(self.generators[idx]) * self.sub_batch_size[idx])\n",
    "                 for idx in range(len(self.sub_batch_size))]) /\n",
    "            self.batch_size)\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Getting items from the generators and packing them\"\"\"\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        for generator in self.generators:\n",
    "            if generator.class_mode is None:\n",
    "                x1 = generator[index % len(generator)]\n",
    "                X_batch = [*X_batch, *x1]\n",
    "            else:\n",
    "                x1, y1 = generator[index % len(generator)]\n",
    "                X_batch = [*X_batch, *x1]\n",
    "                Y_batch = [*Y_batch, *y1]\n",
    "        if self.generators[0].class_mode is None:\n",
    "            return np.array(X_batch)\n",
    "        return np.array(X_batch), np.array(Y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
