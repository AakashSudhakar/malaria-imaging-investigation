{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”· PART 1: Exploratory Data Analysis ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we analyze our given external datasets through a **basic comprehensive** lens: we manipulate, curate, and prepare data in order to ask critical questions and gain an effective understanding of how to perform higher-level prediction-driven data modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”µ TABLE OF CONTENTS ðŸ”µ <a name=\"TOC\"></a>\n",
    "\n",
    "Use this **table of contents** to navigate the various sections of the preprocessing notebook.\n",
    "\n",
    "#### 1. [Section A: Imports and Initializations](#section-A)\n",
    "\n",
    "    All necessary imports and object instantiations for data preprocessing.\n",
    "\n",
    "#### 2. [Section B: Manipulating Our Data](#section-B)\n",
    "\n",
    "    Data manipulation operations, including (but not limited to) \n",
    "    null value imputation and data cleaning. \n",
    "\n",
    "#### 3. [Section C: Visualizing Trends Across Our Data](#section-C)\n",
    "\n",
    "    Data visualizations to outline trends and patterns \n",
    "    inherent across our data that may mandate further analysis.\n",
    "\n",
    "#### 4. [Section D: Saving Our Interim Datasets](#section-D)\n",
    "\n",
    "    Saving preprocessed data states for further access.\n",
    "\n",
    "#### 5. [Appendix: Supplementary Custom Objects](#appendix)\n",
    "\n",
    "    Custom object architectures used throughout the data preprocessing.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section A: Imports and Initializations <a name=\"section-A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Imports for Data Manipulation and Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized Imports for Deep Learning Architectures and Supporting Structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, InputLayer, Reshape, Conv1D, MaxPool1D, SeparableConv2D\n",
    "from keras.applications import MobileNetV2, VGG19\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized Imports for Model Evaluation and Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized Imports for Globular File/Directory Navigation and Script Timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized Imports for Image Modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Algorithmic Structures for Processed Data Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../source/structures\")\n",
    "\n",
    "# TODO: Place custom structures from `../source/structures` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section B: Manipulating Our Data <a name=\"section-B\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATH = \"/Volumes/Bianca/DEVELOPER/data-science/Malaria-Imaging\"\n",
    "RAWPATH, INTPATH = \"datasets/1-raw/cell_images/\", \"datasets/2-interim/cell_images/\"\n",
    "POSITIVE, NEGATIVE = \"Parasitized\", \"Uninfected\"\n",
    "TRAIN, VALID, TEST = \"Training\", \"Validation\", \"Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATHS_RAW = {\n",
    "    POSITIVE: os.path.join(DIRPATH, RAWPATH, POSITIVE),\n",
    "    NEGATIVE: os.path.join(DIRPATH, RAWPATH, NEGATIVE),\n",
    "}\n",
    "\n",
    "DIRPATHS_INT = {\n",
    "    POSITIVE: {\n",
    "        TRAIN: os.path.join(DIRPATH, INTPATH, POSITIVE, TRAIN),\n",
    "        VALID: os.path.join(DIRPATH, INTPATH, POSITIVE, VALID),\n",
    "        TEST:  os.path.join(DIRPATH, INTPATH, POSITIVE, TEST)\n",
    "    },\n",
    "    NEGATIVE: {\n",
    "        TRAIN: os.path.join(DIRPATH, INTPATH, NEGATIVE, TRAIN),\n",
    "        VALID: os.path.join(DIRPATH, INTPATH, NEGATIVE, VALID),\n",
    "        TEST:  os.path.join(DIRPATH, INTPATH, NEGATIVE, TEST)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of interim datasets for ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for position, filename in enumerate(os.listdir(DIRPATHS_RAW[POSITIVE])):\n",
    "    newpath = \"{}_{}.jpg\".format(POSITIVE, position)\n",
    "    source = os.path.join(DIRPATHS_RAW[POSITIVE], filename)\n",
    "    destination = os.path.join(DIRPATH, INTPATH, POSITIVE, newpath)\n",
    "    shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for position, filename in enumerate(os.listdir(DIRPATHS_RAW[NEGATIVE])):\n",
    "    newpath = \"{}_{}.jpg\".format(NEGATIVE, position)\n",
    "    source = os.path.join(DIRPATHS_RAW[NEGATIVE], filename)\n",
    "    destination = os.path.join(DIRPATH, INTPATH, NEGATIVE, newpath)\n",
    "    shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Initialization of Interim Datasets for Ingestion: **Parasitized Images**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\"{}_{}.jpg\".format(POSITIVE, position) for position in range(3000)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, POSITIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[POSITIVE][TRAIN], image)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "images = [\"{}_{}.jpg\".format(POSITIVE, position) for position in range(3000, 4000)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, POSITIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[POSITIVE][VALID], image)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "images = [\"{}_{}.jpg\".format(POSITIVE, position) for position in range(4000, 4500)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, POSITIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[POSITIVE][TEST], image)\n",
    "    shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Initialization of Interim Datasets for Ingestion: **Uninfected Images**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\"{}_{}.jpg\".format(NEGATIVE, position) for position in range(3000)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, NEGATIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[NEGATIVE][TRAIN], image)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "images = [\"{}_{}.jpg\".format(NEGATIVE, position) for position in range(3000, 4000)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, NEGATIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[NEGATIVE][VALID], image)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "images = [\"{}_{}.jpg\".format(NEGATIVE, position) for position in range(4000, 4500)]\n",
    "for image in images:\n",
    "    source = os.path.join(DIRPATH, INTPATH, NEGATIVE, image)\n",
    "    destination = os.path.join(DIRPATHS_INT[NEGATIVE][TEST], image)\n",
    "    shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting Images for Pipeline Ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1.0 / 255.0,\n",
    "                                    validation_split=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation: **Training Data**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SUB_BATCH_SIZE = BATCH_SIZE / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2010 images belonging to 1 classes.\n",
      "Found 2010 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "positive_training_generator = data_generator.flow_from_directory(directory=os.path.join(DIRPATH, INTPATH, POSITIVE),\n",
    "                                                                 classes=[TRAIN], \n",
    "                                                                 target_size=(128, 128),\n",
    "                                                                 class_mode=\"binary\",\n",
    "                                                                 subset=\"training\",\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "negative_training_generator = data_generator.flow_from_directory(directory=os.path.join(DIRPATH, INTPATH, NEGATIVE),\n",
    "                                                                 classes=[TRAIN],\n",
    "                                                                 target_size=(128, 128),\n",
    "                                                                 class_mode=\"binary\",\n",
    "                                                                 subset=\"training\",\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "training_generator = MergedGenerator(BATCH_SIZE, \n",
    "                                     generators=[positive_training_generator, negative_training_generator], \n",
    "                                     sub_batch_size=[SUB_BATCH_SIZE] * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation: **Validation Data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 330 images belonging to 1 classes.\n",
      "Found 330 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "positive_validation_generator = data_generator.flow_from_directory(directory=os.path.join(DIRPATH, INTPATH, POSITIVE),\n",
    "                                                                   classes=[VALID],\n",
    "                                                                   target_size=(128, 128),\n",
    "                                                                   class_mode=\"binary\",\n",
    "                                                                   subset=\"validation\",\n",
    "                                                                   shuffle=True,\n",
    "                                                                   batch_size=32)\n",
    "\n",
    "negative_validation_generator = data_generator.flow_from_directory(directory=os.path.join(DIRPATH, INTPATH, NEGATIVE),\n",
    "                                                                   classes=[VALID],\n",
    "                                                                   target_size=(128, 128),\n",
    "                                                                   class_mode=\"binary\",\n",
    "                                                                   subset=\"validation\",\n",
    "                                                                   shuffle=True,\n",
    "                                                                   batch_size=32)\n",
    "\n",
    "training_generator = MergedGenerator(BATCH_SIZE, \n",
    "                                     generators=[positive_validation_generator, negative_validation_generator], \n",
    "                                     sub_batch_size=[SUB_BATCH_SIZE] * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Instantiation and Testing: **Depth-Wise Separable CNN (DS-CNN)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 126, 126, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 61, 61, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 28, 28, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 12, 12, 128)       8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 311,425\n",
      "Trainable params: 311,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_LENGTH = (128, 128, 3)\n",
    "\n",
    "model_dscnn = Sequential()\n",
    "\n",
    "model_dscnn.add(Conv2D(16, (3, 3), activation=\"relu\", input_shape=INPUT_LENGTH))\n",
    "model_dscnn.add(MaxPool2D(2, 2))\n",
    "model_dscnn.add(Dropout(0.2))\n",
    "\n",
    "model_dscnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model_dscnn.add(MaxPool2D(2, 2))\n",
    "model_dscnn.add(Dropout(0.2))\n",
    "\n",
    "model_dscnn.add(SeparableConv2D(64, (3, 3), activation=\"relu\"))\n",
    "model_dscnn.add(MaxPool2D(2, 2))\n",
    "model_dscnn.add(Dropout(0.3))\n",
    "\n",
    "model_dscnn.add(SeparableConv2D(128, (3, 3), activation=\"relu\"))\n",
    "model_dscnn.add(MaxPool2D(2, 2))\n",
    "model_dscnn.add(Dropout(0.3))\n",
    "\n",
    "model_dscnn.add(Flatten())\n",
    "model_dscnn.add(Dense(64, activation=\"relu\"))\n",
    "model_dscnn.add(Dropout(0.5))\n",
    "\n",
    "model_dscnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model_dscnn.compile(optimizer=optimizer,\n",
    "                    loss=\"binary_crossentropy\",\n",
    "                    metrics=[\"accuracy\"])\n",
    "model_dscnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stoppage = EarlyStopping(monitor=\"val_loss\",\n",
    "                               patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Fulfillment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 6.5808e-06 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class '__main__.MergedGenerator'>\"}), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-7f1bcaefb560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model_dscnn.fit_generator(training_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stoppage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \"\"\"\n\u001b[1;32m   1464\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit_generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1466\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    860\u001b[0m           val_x, val_y, val_sample_weight = (\n\u001b[1;32m    861\u001b[0m               data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0;32m--> 862\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    863\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1047\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p38env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    958\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class '__main__.MergedGenerator'>\"}), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "history = model_dscnn.fit_generator(training_generator,\n",
    "                                    epochs=20,\n",
    "                                    steps_per_epoch=len(training_generator),\n",
    "                                    validation_data=(validation_generator),\n",
    "                                    callbacks=[early_stoppage],\n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of Training and Validation Accuracy Measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-0148ea617d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_training_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay_training_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "display_training_scores(history, which=\"accuracy\")\n",
    "display_training_scores(history, which=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model State Save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Bianca/DEVELOPER/data-science/Malaria-Imaging/models/malaria_imaging_dscnn_v01.h5'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATEPATH, STATEVERSION = \"models\", 1\n",
    "\n",
    "model_state = \"malaria_imaging_dscnn_v{:02d}.h5\".format(STATEVERSION)\n",
    "\n",
    "model_dscnn.save_weights(os.path.join(DIRPATH, STATEPATH, model_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Appendix: Supplementary Custom Objects <a name=\"appendix\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_generator(generator1, generator2):\n",
    "    while True:\n",
    "        yield(next(generator1), next(generator2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_scores(history, which=\"accuracy\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if which == \"accuracy\":\n",
    "        plt.plot(history.history[\"accuracy\"], label=\"Training\", marker=\"*\", linewidth=3)\n",
    "        plt.plot(history.history[\"val_accuracy\"], label=\"Validation\", marker=\"o\", linewidth=3)\n",
    "        plt.title(\"Accuracy Assessment: Training vs. Validation\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "    elif which == \"loss\":\n",
    "        plt.plot(history.history[\"loss\"], label=\"Training\", marker=\"*\", linewidth=3)\n",
    "        plt.plot(history.history[\"val_loss\"], label=\"Validation\", marker=\"o\", linewidth=3)\n",
    "        plt.title(\"Loss Assessment: Training vs. Validation\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend(fontsize=\"x-large\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergedGenerator(Sequence):\n",
    "    def __init__(self, batch_size, generators=[], sub_batch_size=[]):\n",
    "        self.generators = generators\n",
    "        self.sub_batch_size = sub_batch_size\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return int(\n",
    "            sum([(len(self.generators[idx]) * self.sub_batch_size[idx])\n",
    "                 for idx in range(len(self.sub_batch_size))]) /\n",
    "            self.batch_size)\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Getting items from the generators and packing them\"\"\"\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        for generator in self.generators:\n",
    "            if generator.class_mode is None:\n",
    "                x1 = generator[index % len(generator)]\n",
    "                X_batch = [*X_batch, *x1]\n",
    "            else:\n",
    "                x1, y1 = generator[index % len(generator)]\n",
    "                X_batch = [*X_batch, *x1]\n",
    "                Y_batch = [*Y_batch, *y1]\n",
    "        if self.generators[0].class_mode is None:\n",
    "            return np.array(X_batch)\n",
    "        return np.array(X_batch), np.array(Y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
